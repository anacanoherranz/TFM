{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a703f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bf5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basa_full=pd.read_csv('basa_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cce2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aquatic_species = 'Abies,Pinus,Juniperus,Taxus,Betula,Corylus,Alnus,Carpinus,Salix,Ulmus,Populus,Acer,Fraxinus,Fagus,Tilia,Juglans,Castanea,Quercus caducifolio,Quercus perennifolio,Pistacia,Rhamnus,Phillyrea,Buxus,Sambucus,Viburnum,Sanguisorba,Tamarix,Thymelaeaceae,Ephedra distachya,Ephedra fragilis,Ericaceae,Hereda helix,Ilex aquifolium,Viscum album,Lonicera,Vitis,Oleaceae,Myrtus,Olea,Poaceae,Lygeum spartum,Artemisia,Cichorioideae,Asteroideae,Cardueae,Rubiaceae,Centaurea,Chenopodiaceae,Caryophyllaceae,Plantago,Brassicaceae,Saxifragaceae,Fabaceae,Genista,Lotus type,Trifolium type,Rosaceae,Ribes,Boraginaceae,Sedum,Helianthemum,Lamiaceae,Urticaceae,Rumex,Berberidaceae,Euphorbiaceae,Primulaceae,Scrophulariaceae,Papaver,Campanulaceae,Convolvulaceae,Liliaceae,Iridaceae,Crassulaceae,Ranunculaceae,Cistaceae,Galium,Apiaceae,Valerianaceae,Cerealia type,Polygonaceae,Ranunculus'\n",
    "\n",
    "species_mapping = {\n",
    "        \"Dec_Querc\": \"Quercus caducifolio\",\n",
    "        \"Ever_Querc\": \"Quercus perennifolio\",\n",
    "        \"Ephedra dist\": \"Ephedra distachya\",\n",
    "        \"Ephedra frag\": \"Ephedra fragilis\",\n",
    "        \"Lygeum\": \"Lygeum spartum\",\n",
    "        \"Cicho\": \"Cichorioideae\",\n",
    "        \"Astroi\": \"Asteroideae\",\n",
    "        \"Carduaceae\": \"Cardueae\",\n",
    "        \"Rubiac\": \"Rubiaceae\",\n",
    "        \"Chenopo\": \"Chenopodiaceae\",\n",
    "        \"Caryphy\": \"Caryophyllaceae\",\n",
    "        \"Brassicac\": \"Brassicaceae\",\n",
    "        \"Saxifrag\": \"Saxifragaceae\",\n",
    "        \"Boraginac\": \"Boraginaceae\",\n",
    "        \"Helianthem\": \"Helianthemum\",\n",
    "        \"Euphorbiac\": \"Euphorbiaceae\",\n",
    "        \"Primulac\": \"Primulaceae\",\n",
    "        \"Scrophulari\": \"Scrophulariaceae\",\n",
    "        \"Campanulac\": \"Campanulaceae\",\n",
    "        \"Valerian\": \"Valerianaceae\",\n",
    "        \"Cerealia\": \"Cerealia type\",\n",
    "        \"Polygon\": \"Polygonaceae\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8773b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>cal BP</th>\n",
       "      <th>density</th>\n",
       "      <th>accrate</th>\n",
       "      <th>weight</th>\n",
       "      <th>volume</th>\n",
       "      <th>lycadd</th>\n",
       "      <th>lyc</th>\n",
       "      <th>Abies</th>\n",
       "      <th>Pinus</th>\n",
       "      <th>...</th>\n",
       "      <th>Liliaceae</th>\n",
       "      <th>Iridaceae</th>\n",
       "      <th>Crassulaceae</th>\n",
       "      <th>Ranunculaceae</th>\n",
       "      <th>Cistaceae</th>\n",
       "      <th>Galium</th>\n",
       "      <th>Apiaceae</th>\n",
       "      <th>Valerianaceae</th>\n",
       "      <th>Polygonaceae</th>\n",
       "      <th>Ranunculus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-56.90</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>24200</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-50.33</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24200</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.5</td>\n",
       "      <td>-42.11</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>24200</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.5</td>\n",
       "      <td>-30.47</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>24200</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.5</td>\n",
       "      <td>-13.25</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.882353</td>\n",
       "      <td>24200</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  cal BP  density  accrate  weight    volume  lycadd  lyc  Abies  \\\n",
       "0    0.5  -56.90      1.5     0.46     4.3  2.866667   24200   26      1   \n",
       "1    5.5  -50.33      1.7     0.46     3.4  2.000000   24200   12      1   \n",
       "2   10.5  -42.11      1.5     0.46     3.2  2.133333   24200   58      0   \n",
       "3   15.5  -30.47      1.7     0.46     4.0  2.352941   24200   29      0   \n",
       "4   20.5  -13.25      1.7     0.09     3.2  1.882353   24200   17      0   \n",
       "\n",
       "   Pinus  ...  Liliaceae  Iridaceae  Crassulaceae  Ranunculaceae  Cistaceae  \\\n",
       "0    189  ...          2          2             1              2          1   \n",
       "1    149  ...          0          0             0              5          0   \n",
       "2    206  ...          1          1             1              6          0   \n",
       "3    252  ...          0          0             0              4          0   \n",
       "4    141  ...          0          0             0              4          0   \n",
       "\n",
       "   Galium  Apiaceae  Valerianaceae  Polygonaceae  Ranunculus  \n",
       "0       0         0              0             0           1  \n",
       "1       0         1              0             0           3  \n",
       "2       1         2              0             0           5  \n",
       "3       1         0              0             0           2  \n",
       "4       0         3              0             1           3  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_aquatic_species = [s.strip() for s in non_aquatic_species.split(',')]\n",
    "df_bas = df_basa_full[\n",
    "    list(df_basa_full.columns[:8]) +\n",
    "    [c for c in df_basa_full.columns[8:] if c in non_aquatic_species]\n",
    "]\n",
    "\n",
    "df_bas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b8fda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total especies: 79\n",
      "\n",
      "Par√°metros:\n",
      "  Umbral p-value: 0.01\n",
      "  M√≠nimo puntos presencia: 3\n",
      "  Splines base: 140\n",
      "  Lambda: 0.01\n",
      "  Puntos equidistantes: 140\n",
      "============================================================\n",
      "\n",
      "=== RECONSTRUYENDO CON GAM (TIEMPO EQUIDISTANTE) ===\n",
      "  Procesadas 10/79 especies\n",
      "  Procesadas 20/79 especies\n",
      "  Procesadas 30/79 especies\n",
      "  Procesadas 40/79 especies\n",
      "  Procesadas 50/79 especies\n",
      "  Procesadas 60/79 especies\n",
      "  Procesadas 70/79 especies\n",
      "\n",
      "‚úÖ Especies procesadas: 75\n",
      "\n",
      "Datos reconstruidos: 140 puntos\n",
      "Rango cal BP: -57 - 9798\n",
      "\n",
      "=== DEFINICI√ìN DE VENTANAS (tiempo equidistante) ===\n",
      "  9798_6253: cal BP 6253 - 9798 (filas 89-139)\n",
      "  6182_3842: cal BP 3843 - 6111 (filas 55-87)\n",
      "  3771_-57: cal BP -57 - 3701 (filas 0-53)\n",
      "\n",
      "Especies v√°lidas para Granger: 75\n",
      "\n",
      "==================================================\n",
      "VENTANA: 9798_6253\n",
      "==================================================\n",
      "  Filas 89-139 (51 puntos)\n",
      "  Rango cal BP: 6253 - 9798\n",
      "  Pares analizados: 5550\n",
      "  Links significativos (p<0.01): 201 (3.62%)\n",
      "    Positivos: 184 (91.5%)\n",
      "    Negativos: 17 (8.5%)\n",
      "\n",
      "==================================================\n",
      "VENTANA: 6182_3842\n",
      "==================================================\n",
      "  Filas 55-87 (33 puntos)\n",
      "  Rango cal BP: 3843 - 6111\n",
      "  Pares analizados: 5550\n",
      "  Links significativos (p<0.01): 307 (5.53%)\n",
      "    Positivos: 228 (74.3%)\n",
      "    Negativos: 79 (25.7%)\n",
      "\n",
      "==================================================\n",
      "VENTANA: 3771_-57\n",
      "==================================================\n",
      "  Filas 0-53 (54 puntos)\n",
      "  Rango cal BP: -57 - 3701\n",
      "  Pares analizados: 5550\n",
      "  Links significativos (p<0.01): 166 (2.99%)\n",
      "    Positivos: 134 (80.7%)\n",
      "    Negativos: 32 (19.3%)\n",
      "\n",
      "======================================================================\n",
      "COMPARACI√ìN CON RESULTADOS DEL PAPER\n",
      "======================================================================\n",
      "\n",
      "Ventana        | Obtenido       | Esperado       | Diferencia\n",
      "----------------------------------------------------------------------\n",
      "9798_6253    | 201 links ( 8.5%) | 161 links ( 9.9%) | links: +40, %: -1.4\n",
      "6182_3842    | 307 links (25.7%) | 252 links (29.8%) | links: +55, %: -4.1\n",
      "3771_-57     | 166 links (19.3%) | 155 links (22.6%) | links: +11, %: -3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.api import VAR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================\n",
    "\n",
    "especies_cols = df_bas.columns[df_bas.columns.get_loc('Abies'):].tolist()\n",
    "print(f\"Total especies: {len(especies_cols)}\")\n",
    "\n",
    "# PAR√ÅMETROS\n",
    "UMBRAL_P_VALUE = 0.01\n",
    "MIN_PRESENCIA = 3\n",
    "\n",
    "# GAM\n",
    "N_SPLINES_BASE = 140\n",
    "LAMBDA_GAM = 0.01\n",
    "N_PUNTOS_EQUIDISTANTES = 140  # Mismo n√∫mero de puntos\n",
    "\n",
    "print(f\"\\nPar√°metros:\")\n",
    "print(f\"  Umbral p-value: {UMBRAL_P_VALUE}\")\n",
    "print(f\"  M√≠nimo puntos presencia: {MIN_PRESENCIA}\")\n",
    "print(f\"  Splines base: {N_SPLINES_BASE}\")\n",
    "print(f\"  Lambda: {LAMBDA_GAM}\")\n",
    "print(f\"  Puntos equidistantes: {N_PUNTOS_EQUIDISTANTES}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# FUNCIONES\n",
    "# ============================================\n",
    "\n",
    "def es_serie_valida(serie):\n",
    "    \"\"\"Verifica si una serie es v√°lida para an√°lisis\"\"\"\n",
    "    n_presencia = (serie > 0).sum()\n",
    "    if n_presencia < MIN_PRESENCIA:\n",
    "        return False\n",
    "    if serie.nunique() < 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def reconstruir_gam_equidistante(df_original, n_puntos=140):\n",
    "    \"\"\"\n",
    "    Reconstruye con GAM y genera tiempo EQUIDISTANTE\n",
    "    \"\"\"\n",
    "    tiempo_original = df_original['cal BP'].values\n",
    "    \n",
    "    # Crear tiempo equidistante (de antiguo a reciente)\n",
    "    tiempo_equidistante = np.linspace(tiempo_original.min(), tiempo_original.max(), n_puntos)\n",
    "    \n",
    "    df_reconstruido = pd.DataFrame({'cal BP': tiempo_equidistante})\n",
    "    \n",
    "    print(\"\\n=== RECONSTRUYENDO CON GAM (TIEMPO EQUIDISTANTE) ===\")\n",
    "    \n",
    "    especies_procesadas = 0\n",
    "    \n",
    "    for idx, sp in enumerate(especies_cols):\n",
    "        if idx % 10 == 0 and idx > 0:\n",
    "            print(f\"  Procesadas {idx}/{len(especies_cols)} especies\")\n",
    "            \n",
    "        serie = df_original[sp].copy()\n",
    "        \n",
    "        if not es_serie_valida(serie):\n",
    "            continue\n",
    "        \n",
    "        # Puntos originales (con tiempo original)\n",
    "        tiempo_valido = tiempo_original.reshape(-1, 1)\n",
    "        valores = serie.values\n",
    "        \n",
    "        try:\n",
    "            # GAM\n",
    "            gam = LinearGAM(s(0, n_splines=N_SPLINES_BASE, lam=LAMBDA_GAM))\n",
    "            gam.fit(tiempo_valido, valores)\n",
    "            \n",
    "            # Predecir en tiempo EQUIDISTANTE\n",
    "            tiempo_pred = tiempo_equidistante.reshape(-1, 1)\n",
    "            predicciones = gam.predict(tiempo_pred)\n",
    "            predicciones = np.maximum(predicciones, 0)\n",
    "            \n",
    "            df_reconstruido[sp] = predicciones\n",
    "            especies_procesadas += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Si falla, interpolar linealmente en tiempo equidistante\n",
    "            from scipy.interpolate import interp1d\n",
    "            try:\n",
    "                f = interp1d(tiempo_original, valores, kind='linear', \n",
    "                            fill_value='extrapolate', bounds_error=False)\n",
    "                predicciones = f(tiempo_equidistante)\n",
    "                predicciones = np.maximum(predicciones, 0)\n",
    "                df_reconstruido[sp] = predicciones\n",
    "            except:\n",
    "                df_reconstruido[sp] = np.mean(valores)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Especies procesadas: {especies_procesadas}\")\n",
    "    \n",
    "    # Ordenar de antiguo a reciente\n",
    "    df_reconstruido = df_reconstruido.sort_values('cal BP', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    return df_reconstruido\n",
    "\n",
    "def definir_ventanas_equidistantes(df_reconstruido):\n",
    "    \"\"\"\n",
    "    Define ventanas en el tiempo EQUIDISTANTE basado en los valores de cal BP\n",
    "    \"\"\"\n",
    "    cal_values = df_reconstruido['cal BP'].values\n",
    "    \n",
    "    # Rangos deseados\n",
    "    rangos = [\n",
    "        (\"9798_6253\", 9798, 6253),\n",
    "        (\"6182_3842\", 6182, 3842),\n",
    "        (\"3771_-57\", 3771, -57)\n",
    "    ]\n",
    "    \n",
    "    windows = {}\n",
    "    for name, cal_max, cal_min in rangos:\n",
    "        # Encontrar √≠ndices que corresponden a estos cal BP\n",
    "        mask = (cal_values <= cal_max) & (cal_values >= cal_min)\n",
    "        indices = np.where(mask)[0]\n",
    "        \n",
    "        if len(indices) > 0:\n",
    "            windows[name] = (indices[0], indices[-1])\n",
    "            print(f\"  {name}: cal BP {cal_values[indices[0]]:.0f} - {cal_values[indices[-1]]:.0f} \"\n",
    "                  f\"(filas {indices[0]}-{indices[-1]})\")\n",
    "    \n",
    "    return windows\n",
    "\n",
    "def calcular_granger(df_window, especies_validas):\n",
    "    \"\"\"Calcula causalidad de Granger\"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for i, sp1 in enumerate(especies_validas):\n",
    "        for j, sp2 in enumerate(especies_validas):\n",
    "            if i != j:\n",
    "                try:\n",
    "                    array_x = df_window[sp1].values[::-1]\n",
    "                    array_y = df_window[sp2].values[::-1]\n",
    "                    \n",
    "                    # Ruido adaptativo\n",
    "                    ruido_x = np.random.normal(0, np.std(array_x) * 1e-6, len(array_x))\n",
    "                    ruido_y = np.random.normal(0, np.std(array_y) * 1e-6, len(array_y))\n",
    "                    \n",
    "                    array_x = array_x + ruido_x\n",
    "                    array_y = array_y + ruido_y\n",
    "                    \n",
    "                    # VAR\n",
    "                    data = pd.DataFrame({sp1: array_x, sp2: array_y})\n",
    "                    scaler = StandardScaler()\n",
    "                    data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "                    \n",
    "                    model = VAR(data_scaled)\n",
    "                    results = model.fit(maxlags=1)\n",
    "                    \n",
    "                    causality = results.test_causality(caused=sp2, causing=[sp1], kind='f')\n",
    "                    p_value = causality.pvalue\n",
    "                    coeficiente = results.coefs[0][1][0]\n",
    "                    \n",
    "                    resultados.append({\n",
    "                        'from': sp1,\n",
    "                        'to': sp2,\n",
    "                        'p_value': p_value,\n",
    "                        'coeficiente': coeficiente,\n",
    "                        'signo': 'positivo' if coeficiente > 0 else 'negativo'\n",
    "                    })\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# ============================================\n",
    "# EJECUCI√ìN PRINCIPAL\n",
    "# ============================================\n",
    "\n",
    "# 1. Reconstruir con GAM en tiempo EQUIDISTANTE\n",
    "df_equidistante = reconstruir_gam_equidistante(df_bas, N_PUNTOS_EQUIDISTANTES)\n",
    "\n",
    "print(f\"\\nDatos reconstruidos: {len(df_equidistante)} puntos\")\n",
    "print(f\"Rango cal BP: {df_equidistante['cal BP'].min():.0f} - {df_equidistante['cal BP'].max():.0f}\")\n",
    "\n",
    "# 2. Definir ventanas en el NUEVO tiempo equidistante\n",
    "print(\"\\n=== DEFINICI√ìN DE VENTANAS (tiempo equidistante) ===\")\n",
    "windows_equidistantes = definir_ventanas_equidistantes(df_equidistante)\n",
    "\n",
    "# 3. Identificar especies v√°lidas (usando datos originales)\n",
    "especies_validas = []\n",
    "for sp in especies_cols:\n",
    "    if es_serie_valida(df_bas[sp]):\n",
    "        especies_validas.append(sp)\n",
    "\n",
    "print(f\"\\nEspecies v√°lidas para Granger: {len(especies_validas)}\")\n",
    "\n",
    "# 4. Calcular Granger en cada ventana\n",
    "resultados = {}\n",
    "\n",
    "for window_name, (start, end) in windows_equidistantes.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"VENTANA: {window_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df_window = df_equidistante.iloc[start:end+1].copy()\n",
    "    print(f\"  Filas {start}-{end} ({len(df_window)} puntos)\")\n",
    "    print(f\"  Rango cal BP: {df_window['cal BP'].min():.0f} - {df_window['cal BP'].max():.0f}\")\n",
    "    \n",
    "    df_res = calcular_granger(df_window, especies_validas)\n",
    "    resultados[window_name] = df_res\n",
    "    \n",
    "    if len(df_res) > 0:\n",
    "        sig = df_res[df_res['p_value'] < UMBRAL_P_VALUE]\n",
    "        n_sig = len(sig)\n",
    "        print(f\"  Pares analizados: {len(df_res)}\")\n",
    "        print(f\"  Links significativos (p<{UMBRAL_P_VALUE}): {n_sig} ({n_sig/len(df_res)*100:.2f}%)\")\n",
    "        \n",
    "        if n_sig > 0:\n",
    "            n_pos = len(sig[sig['signo'] == 'positivo'])\n",
    "            n_neg = len(sig[sig['signo'] == 'negativo'])\n",
    "            print(f\"    Positivos: {n_pos} ({n_pos/n_sig*100:.1f}%)\")\n",
    "            print(f\"    Negativos: {n_neg} ({n_neg/n_sig*100:.1f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# COMPARACI√ìN CON RESULTADOS ESPERADOS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN CON RESULTADOS DEL PAPER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "esperados = {\n",
    "    \"9798_6253\": {\"links\": 161, \"pct_neg\": 9.9},\n",
    "    \"6182_3842\": {\"links\": 252, \"pct_neg\": 29.8},\n",
    "    \"3771_-57\": {\"links\": 155, \"pct_neg\": 22.6}\n",
    "}\n",
    "\n",
    "print(\"\\nVentana        | Obtenido       | Esperado       | Diferencia\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for window_name in windows_equidistantes.keys():\n",
    "    if window_name in resultados and len(resultados[window_name]) > 0:\n",
    "        df_res = resultados[window_name]\n",
    "        sig = df_res[df_res['p_value'] < UMBRAL_P_VALUE]\n",
    "        n_sig = len(sig)\n",
    "        \n",
    "        if n_sig > 0:\n",
    "            n_neg = len(sig[sig['signo'] == 'negativo'])\n",
    "            pct_neg = n_neg / n_sig * 100\n",
    "        else:\n",
    "            n_sig = 0\n",
    "            pct_neg = 0\n",
    "        \n",
    "        exp = esperados.get(window_name, {\"links\": 0, \"pct_neg\": 0})\n",
    "        \n",
    "        diff_links = n_sig - exp[\"links\"]\n",
    "        diff_pct = pct_neg - exp[\"pct_neg\"]\n",
    "        \n",
    "        print(f\"{window_name:12} | {n_sig:3} links ({pct_neg:4.1f}%) | \"\n",
    "              f\"{exp['links']:3} links ({exp['pct_neg']:4.1f}%) | \"\n",
    "              f\"links: {diff_links:+d}, %: {diff_pct:+.1f}\")\n",
    "    else:\n",
    "        print(f\"{window_name:12} | Sin datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00062a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GUARDANDO DATOS EQUIDISTANTES\n",
      "============================================================\n",
      "DataFrame equidistante:\n",
      "  Forma: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus', 'Betula', 'Corylus', 'Alnus', 'Carpinus', 'Salix', 'Ulmus', 'Populus', 'Acer', 'Fraxinus', 'Fagus', 'Tilia', 'Juglans', 'Castanea', 'Pistacia', 'Rhamnus', 'Buxus', 'Sambucus', 'Viburnum', 'Tamarix', 'Thymelaeaceae', 'Ephedra distachya', 'Ephedra fragilis', 'Ericaceae', 'Hereda helix', 'Ilex aquifolium', 'Lonicera', 'Vitis', 'Oleaceae', 'Myrtus', 'Olea', 'Poaceae', 'Artemisia', 'Cichorioideae', 'Asteroideae', 'Cardueae', 'Rubiaceae', 'Centaurea', 'Chenopodiaceae', 'Caryophyllaceae', 'Plantago', 'Brassicaceae', 'Saxifragaceae', 'Fabaceae', 'Genista', 'Lotus type', 'Trifolium type', 'Rosaceae', 'Ribes', 'Boraginaceae', 'Sedum', 'Helianthemum', 'Lamiaceae', 'Urticaceae', 'Rumex', 'Berberidaceae', 'Euphorbiaceae', 'Primulaceae', 'Scrophulariaceae', 'Papaver', 'Campanulaceae', 'Convolvulaceae', 'Liliaceae', 'Iridaceae', 'Crassulaceae', 'Ranunculaceae', 'Cistaceae', 'Galium', 'Apiaceae', 'Valerianaceae', 'Polygonaceae', 'Ranunculus']\n",
      "  Rango cal BP: -57 - 9798\n",
      "  N√∫mero de puntos: 140\n",
      "\n",
      "‚úÖ Datos guardados en 'gam_original.pkl' (formato pickle)\n",
      "\n",
      "============================================================\n",
      "VERIFICANDO CARGA DE DATOS\n",
      "============================================================\n",
      "Pickle - cargado: (140, 76), cal BP: -57 - 9798\n",
      "\n",
      "============================================================\n",
      "METADATOS\n",
      "============================================================\n",
      "\n",
      "Metadatos del archivo:\n",
      "  fecha_generacion: 2026-02-18 19:28:27\n",
      "  n_puntos_original: 140\n",
      "  n_puntos_equidistante: 140\n",
      "  n_especies: 75\n",
      "  rango_cal_BP: -57 - 9798\n",
      "  parametros_gam:\n",
      "    n_splines: 140\n",
      "    lambda: 0.01\n",
      "    min_presencia: 3\n",
      "\n",
      "‚úÖ Metadatos guardados en 'metadatos_equidistantes.txt'\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GUARDAR DATOS EQUIDISTANTES TRAS GAM\n",
    "# ============================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Despu√©s de obtener df_equidistante de la funci√≥n reconstruir_gam_equidistante()\n",
    "# df_equidistante = reconstruir_gam_equidistante(df_bas, N_PUNTOS_EQUIDISTANTES)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GUARDANDO DATOS EQUIDISTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"DataFrame equidistante:\")\n",
    "print(f\"  Forma: {df_equidistante.shape}\")\n",
    "print(f\"  Columnas: {df_equidistante.columns.tolist()}\")\n",
    "print(f\"  Rango cal BP: {df_equidistante['cal BP'].min():.0f} - {df_equidistante['cal BP'].max():.0f}\")\n",
    "print(f\"  N√∫mero de puntos: {len(df_equidistante)}\")\n",
    "\n",
    "# ============================================\n",
    "# OPCI√ìN 1: Guardar con pickle (formato binario nativo de Python)\n",
    "# ============================================\n",
    "\n",
    "with open('pkl/gam_original.pkl', 'wb') as f:\n",
    "    pickle.dump(df_equidistante, f)\n",
    "\n",
    "print(\"\\n‚úÖ Datos guardados en 'gam_original.pkl' (formato pickle)\")\n",
    "\n",
    "# ============================================\n",
    "# VERIFICAR QUE SE GUARD√ì CORRECTAMENTE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICANDO CARGA DE DATOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar con pickle\n",
    "with open('pkl/gam_original.pkl', 'rb') as f:\n",
    "    df_cargado_pickle = pickle.load(f)\n",
    "\n",
    "print(f\"Pickle - cargado: {df_cargado_pickle.shape}, \"\n",
    "      f\"cal BP: {df_cargado_pickle['cal BP'].min():.0f} - {df_cargado_pickle['cal BP'].max():.0f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# INFORMACI√ìN PARA FUTUROS AN√ÅLISIS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METADATOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metadata = {\n",
    "    'fecha_generacion': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'n_puntos_original': len(df_bas),\n",
    "    'n_puntos_equidistante': len(df_equidistante),\n",
    "    'n_especies': len(especies_cols),\n",
    "    'rango_cal_BP': f\"{df_equidistante['cal BP'].min():.0f} - {df_equidistante['cal BP'].max():.0f}\",\n",
    "    'parametros_gam': {\n",
    "        'n_splines': N_SPLINES_BASE,\n",
    "        'lambda': LAMBDA_GAM,\n",
    "        'min_presencia': MIN_PRESENCIA\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nMetadatos del archivo:\")\n",
    "for key, value in metadata.items():\n",
    "    if key != 'parametros_gam':\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "\n",
    "# Guardar metadatos en archivo de texto\n",
    "with open('metadatos_equidistantes.txt', 'w') as f:\n",
    "    f.write(\"METADATOS - DATOS EQUIDISTANTES GAM\\n\")\n",
    "    f.write(\"=\"*40 + \"\\n\")\n",
    "    for key, value in metadata.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Metadatos guardados en 'metadatos_equidistantes.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16b33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BOOTSTRAP ESTACIONARIO\n",
      "============================================================\n",
      "Longitud de la serie (L): 140\n",
      "N√∫mero de bootstraps: 5\n",
      "Lambda distribuci√≥n exponencial: 0.0071\n",
      "============================================================\n",
      "\n",
      "Especies disponibles para bootstrap: 75\n",
      "\n",
      "==================================================\n",
      "GENERANDO BOOTSTRAP #1\n",
      "==================================================\n",
      "  Dimensiones: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus']...\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_1.pkl\n",
      "\n",
      "  Primeros valores de especies ejemplo:\n",
      "    Abies: [0.61271431 0.20884143 0.         0.02506226 0.        ]\n",
      "    Pinus: [121.52079654 145.23044146 146.71232116  95.49331131 106.9890442 ]\n",
      "    Juniperus: [4.46750261 3.8380869  3.95351712 3.55912202 4.70149744]\n",
      "    Taxus: [3.31136103e-04 0.00000000e+00 0.00000000e+00 2.92538639e-10\n",
      " 2.50699598e-09]\n",
      "    Betula: [1.27731334 6.84360917 9.25204574 4.65463797 2.08368075]\n",
      "\n",
      "==================================================\n",
      "GENERANDO BOOTSTRAP #2\n",
      "==================================================\n",
      "  Dimensiones: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus']...\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_2.pkl\n",
      "\n",
      "  Primeros valores de especies ejemplo:\n",
      "    Abies: [0.00000000e+00 1.22188357e-02 1.12886580e-01 0.00000000e+00\n",
      " 1.59805205e-08]\n",
      "    Pinus: [219.4679197  146.72401211 157.73398858 160.53622466 107.45016462]\n",
      "    Juniperus: [9.28490308 7.61213828 5.86751497 5.41913734 7.68877517]\n",
      "    Taxus: [5.88665824e-10 2.08621164e-09 1.78123617e-10 7.31049318e-11\n",
      " 1.29277426e-08]\n",
      "    Betula: [95.43421718 80.57519916 20.01604419 21.40928573 23.57385609]\n",
      "\n",
      "==================================================\n",
      "GENERANDO BOOTSTRAP #3\n",
      "==================================================\n",
      "  Dimensiones: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus']...\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_3.pkl\n",
      "\n",
      "  Primeros valores de especies ejemplo:\n",
      "    Abies: [7.15857196 6.19484215 4.67456339 3.3125462  2.68594661]\n",
      "    Pinus: [108.66591045 116.13753808 118.46569884  90.18733518  73.18313348]\n",
      "    Juniperus: [6.18424674 6.6990729  4.18326817 7.44415209 8.42292522]\n",
      "    Taxus: [9.81727306e-07 0.00000000e+00 1.93835872e-06 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "    Betula: [20.463005   20.01604419 21.40928573 23.57385609 24.12328601]\n",
      "\n",
      "==================================================\n",
      "GENERANDO BOOTSTRAP #4\n",
      "==================================================\n",
      "  Dimensiones: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus']...\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_4.pkl\n",
      "\n",
      "  Primeros valores de especies ejemplo:\n",
      "    Abies: [4.08137628 1.58333558 0.78195753 2.13677531 3.57006457]\n",
      "    Pinus: [140.01365869 123.08657274 134.45905614 150.27012624 121.52079654]\n",
      "    Juniperus: [2.29586178 2.32631507 4.4086026  6.14822668 6.05943813]\n",
      "    Taxus: [9.81727306e-07 0.00000000e+00 1.93835872e-06 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "    Betula: [23.81235266 28.63099231 38.58741591 56.24652829 80.49084489]\n",
      "\n",
      "==================================================\n",
      "GENERANDO BOOTSTRAP #5\n",
      "==================================================\n",
      "  Dimensiones: (140, 76)\n",
      "  Columnas: ['cal BP', 'Abies', 'Pinus', 'Juniperus', 'Taxus']...\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_5.pkl\n",
      "\n",
      "  Primeros valores de especies ejemplo:\n",
      "    Abies: [9.20838794 7.91493132 6.21991772 5.26148169 5.24087364]\n",
      "    Pinus: [93.80687103 92.29172557 96.83042307 97.81881848 91.60518506]\n",
      "    Juniperus: [3.8380869  3.95351712 3.55912202 4.70149744 8.54210811]\n",
      "    Taxus: [0.         0.00859085 0.         0.         0.56121635]\n",
      "    Betula: [20.463005   20.01604419 21.40928573 23.57385609 24.12328601]\n",
      "\n",
      "============================================================\n",
      "VERIFICACI√ìN DE ARCHIVOS GENERADOS\n",
      "============================================================\n",
      "\n",
      "Archivos encontrados en carpeta 'pkl/':\n",
      "  üìÑ pkl/gam_boost_1.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_2.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_3.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_4.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_5.pkl (88.7 KB)\n",
      "\n",
      "‚úÖ √âXITO: Se generaron los 5 archivos bootstrap\n",
      "\n",
      "============================================================\n",
      "EJEMPLO DE CARGA\n",
      "============================================================\n",
      "‚úÖ Cargado bootstrap #1\n",
      "\n",
      "  Dimensiones: (140, 76)\n",
      "  Rango cal BP: -57 - 9798\n",
      "\n",
      "  Primeras 3 filas:\n",
      "      cal BP     Abies       Pinus  Juniperus\n",
      "0 -56.900000  0.612714  121.520797   4.467503\n",
      "1  13.998561  0.208841  145.230441   3.838087\n",
      "2  84.897122  0.000000  146.712321   3.953517\n",
      "\n",
      "============================================================\n",
      "‚úÖ PROCESO COMPLETADO\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACI√ìN DEL BOOTSTRAP ESTACIONARIO\n",
    "# ============================================\n",
    "\n",
    "# Crear carpeta para guardar los archivos\n",
    "os.makedirs('pkl', exist_ok=True)\n",
    "\n",
    "L = 140  # Longitud de la serie temporal\n",
    "N_BOOTSTRAP = 5  # N√∫mero de matrices bootstrap\n",
    "lambda_exp = 1/L  # Par√°metro para la distribuci√≥n exponencial\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BOOTSTRAP ESTACIONARIO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Longitud de la serie (L): {L}\")\n",
    "print(f\"N√∫mero de bootstraps: {N_BOOTSTRAP}\")\n",
    "print(f\"Lambda distribuci√≥n exponencial: {lambda_exp:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# FUNCI√ìN PARA GENERAR UNA SERIE BOOTSTRAP\n",
    "# ============================================\n",
    "\n",
    "def generar_serie_bootstrap(serie_original, L, lambda_exp):\n",
    "    \"\"\"\n",
    "    Genera una serie bootstrap usando el m√©todo de bootstrap estacionario\n",
    "    \n",
    "    Par√°metros:\n",
    "    - serie_original: array de longitud L con la serie temporal original\n",
    "    - L: longitud de la serie\n",
    "    - lambda_exp: par√°metro para la distribuci√≥n exponencial\n",
    "    \n",
    "    Retorna:\n",
    "    - serie_bootstrap: array de longitud L con la serie bootstrap\n",
    "    \"\"\"\n",
    "    \n",
    "    serie_bootstrap = np.zeros(L)\n",
    "    pos = 0\n",
    "    \n",
    "    while pos < L:\n",
    "        # 1. Elegir m (punto de inicio) uniformemente\n",
    "        m = np.random.randint(0, L)\n",
    "        \n",
    "        # 2. Elegir l (longitud del bloque) con distribuci√≥n exponencial\n",
    "        l = int(np.random.exponential(scale=1/lambda_exp))\n",
    "        l = min(l, L)  # Asegurar que no excede L\n",
    "        \n",
    "        # 3. Copiar el bloque de longitud l desde m\n",
    "        for i in range(l):\n",
    "            if pos >= L:\n",
    "                break\n",
    "                \n",
    "            # Calcular √≠ndice en la serie original (con wrap-around)\n",
    "            idx_original = (m + i) % L\n",
    "            serie_bootstrap[pos] = serie_original[idx_original]\n",
    "            pos += 1\n",
    "    \n",
    "    return serie_bootstrap\n",
    "\n",
    "def generar_bootstrap_completo(df_equidistante, especies_cols, L, lambda_exp):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame bootstrap completo con todas las especies\n",
    "    \"\"\"\n",
    "    # Crear DataFrame vac√≠o con la misma estructura\n",
    "    df_bootstrap = pd.DataFrame()\n",
    "    df_bootstrap['cal BP'] = df_equidistante['cal BP'].values  # Mantener el tiempo\n",
    "    \n",
    "    # Para cada especie, generar su serie bootstrap\n",
    "    for sp in especies_cols:\n",
    "        if sp in df_equidistante.columns:\n",
    "            serie_original = df_equidistante[sp].values\n",
    "            serie_bootstrap = generar_serie_bootstrap(serie_original, L, lambda_exp)\n",
    "            df_bootstrap[sp] = serie_bootstrap\n",
    "    \n",
    "    return df_bootstrap\n",
    "\n",
    "# ============================================\n",
    "# GENERAR Y GUARDAR LOS 5 BOOTSTRAPS\n",
    "# ============================================\n",
    "\n",
    "# Asegurarnos de que df_equidistante existe\n",
    "# Si no, cargarlo (asumiendo que est√° en el entorno)\n",
    "if 'df_equidistante' not in locals() and 'df_equidistante' not in globals():\n",
    "    print(\"\\nCargando datos equidistantes...\")\n",
    "    try:\n",
    "        with open('datos_equidistantes_gam.pkl', 'rb') as f:\n",
    "            df_equidistante = pickle.load(f)\n",
    "        print(\"‚úÖ Datos cargados correctamente\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Error: No se encuentra el archivo 'datos_equidistantes_gam.pkl'\")\n",
    "        print(\"   Aseg√∫rate de haber ejecutado primero el c√≥digo de GAM\")\n",
    "        exit()\n",
    "\n",
    "# Verificar que tenemos las columnas de especies\n",
    "especies_cols_bootstrap = [col for col in especies_cols if col in df_equidistante.columns]\n",
    "print(f\"\\nEspecies disponibles para bootstrap: {len(especies_cols_bootstrap)}\")\n",
    "\n",
    "# Fijar semilla para reproducibilidad (opcional)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generar y guardar cada bootstrap\n",
    "for i in range(1, N_BOOTSTRAP + 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"GENERANDO BOOTSTRAP #{i}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Generar bootstrap\n",
    "    df_bootstrap = generar_bootstrap_completo(df_equidistante, especies_cols_bootstrap, L, lambda_exp)\n",
    "    \n",
    "    # Verificar dimensiones\n",
    "    print(f\"  Dimensiones: {df_bootstrap.shape}\")\n",
    "    print(f\"  Columnas: {df_bootstrap.columns.tolist()[:5]}...\")\n",
    "    \n",
    "    # Guardar en archivo pickle\n",
    "    filename = f'pkl/gam_boost_{i}.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(df_bootstrap, f)\n",
    "    \n",
    "    print(f\"  ‚úÖ Guardado en: {filename}\")\n",
    "    \n",
    "    # Verificaci√≥n r√°pida (mostrar primeros valores de algunas especies)\n",
    "    print(f\"\\n  Primeros valores de especies ejemplo:\")\n",
    "    especies_ejemplo = df_bootstrap.columns[1:6].tolist()\n",
    "    for sp in especies_ejemplo:\n",
    "        if sp in df_bootstrap.columns:\n",
    "            print(f\"    {sp}: {df_bootstrap[sp].values[:5]}\")\n",
    "\n",
    "# ============================================\n",
    "# VERIFICACI√ìN FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICACI√ìN DE ARCHIVOS GENERADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "archivos_generados = []\n",
    "for i in range(1, N_BOOTSTRAP + 1):\n",
    "    filename = f'pkl/gam_boost_{i}.pkl'\n",
    "    if os.path.exists(filename):\n",
    "        size_kb = os.path.getsize(filename) / 1024\n",
    "        archivos_generados.append((filename, size_kb))\n",
    "\n",
    "print(f\"\\nArchivos encontrados en carpeta 'pkl/':\")\n",
    "for filename, size in archivos_generados:\n",
    "    print(f\"  üìÑ {filename} ({size:.1f} KB)\")\n",
    "\n",
    "if len(archivos_generados) == N_BOOTSTRAP:\n",
    "    print(f\"\\n‚úÖ √âXITO: Se generaron los {N_BOOTSTRAP} archivos bootstrap\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è ERROR: Solo se generaron {len(archivos_generados)} de {N_BOOTSTRAP} archivos\")\n",
    "\n",
    "# ============================================\n",
    "# FUNCI√ìN PARA CARGAR UN BOOTSTRAP ESPEC√çFICO\n",
    "# ============================================\n",
    "\n",
    "def cargar_bootstrap(numero):\n",
    "    \"\"\"\n",
    "    Carga un archivo bootstrap espec√≠fico\n",
    "    \"\"\"\n",
    "    filename = f'pkl/gam_boost_{numero}.pkl'\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Cargado bootstrap #{numero}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå No se encuentra el archivo: {filename}\")\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EJEMPLO DE CARGA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar el primer bootstrap como ejemplo\n",
    "df_ejemplo = cargar_bootstrap(1)\n",
    "if df_ejemplo is not None:\n",
    "    print(f\"\\n  Dimensiones: {df_ejemplo.shape}\")\n",
    "    print(f\"  Rango cal BP: {df_ejemplo['cal BP'].min():.0f} - {df_ejemplo['cal BP'].max():.0f}\")\n",
    "    print(f\"\\n  Primeras 3 filas:\")\n",
    "    print(df_ejemplo[['cal BP'] + especies_ejemplo[:3]].head(3).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PROCESO COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04766e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCRIPT 1: GENERANDO BOOTSTRAPS ESTACIONARIOS\n",
      "============================================================\n",
      "\n",
      "Cargando datos equidistantes...\n",
      "Especies disponibles: 75\n",
      "\n",
      "Par√°metros:\n",
      "  Longitud serie (L): 140\n",
      "  N√∫mero bootstraps: 5\n",
      "  Lambda exponencial: 0.0071\n",
      "\n",
      "============================================================\n",
      "GENERANDO BOOTSTRAPS\n",
      "============================================================\n",
      "\n",
      "--- Bootstrap #1 ---\n",
      "  Dimensiones: (140, 76)\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_1.pkl\n",
      "\n",
      "--- Bootstrap #2 ---\n",
      "  Dimensiones: (140, 76)\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_2.pkl\n",
      "\n",
      "--- Bootstrap #3 ---\n",
      "  Dimensiones: (140, 76)\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_3.pkl\n",
      "\n",
      "--- Bootstrap #4 ---\n",
      "  Dimensiones: (140, 76)\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_4.pkl\n",
      "\n",
      "--- Bootstrap #5 ---\n",
      "  Dimensiones: (140, 76)\n",
      "  ‚úÖ Guardado en: pkl/gam_boost_5.pkl\n",
      "\n",
      "============================================================\n",
      "VERIFICACI√ìN DE ARCHIVOS\n",
      "============================================================\n",
      "\n",
      "Archivos en carpeta 'pkl/':\n",
      "  üìÑ pkl/gam_boost_1.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_2.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_3.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_4.pkl (88.7 KB)\n",
      "  üìÑ pkl/gam_boost_5.pkl (88.7 KB)\n",
      "\n",
      "‚úÖ √âXITO: Se generaron los 5 archivos bootstrap\n",
      "\n",
      "============================================================\n",
      "SCRIPT 1 COMPLETADO\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SCRIPT 1: GENERAR BOOTSTRAPS ESTACIONARIOS\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCRIPT 1: GENERANDO BOOTSTRAPS ESTACIONARIOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================\n",
    "\n",
    "# Crear carpeta para guardar los archivos\n",
    "os.makedirs('pkl', exist_ok=True)\n",
    "\n",
    "L = 140  # Longitud de la serie temporal\n",
    "N_BOOTSTRAP = 5  # N√∫mero de matrices bootstrap (cambiar a 1000 despu√©s)\n",
    "lambda_exp = 1/L  # Par√°metro para la distribuci√≥n exponencial\n",
    "\n",
    "# Cargar datos originales equidistantes\n",
    "print(\"\\nCargando datos equidistantes...\")\n",
    "with open('pkl/gam_original.pkl', 'rb') as f:\n",
    "    df_original = pickle.load(f)\n",
    "\n",
    "# Identificar especies (excluyendo 'cal BP')\n",
    "especies_cols = [col for col in df_original.columns if col != 'cal BP']\n",
    "print(f\"Especies disponibles: {len(especies_cols)}\")\n",
    "\n",
    "print(f\"\\nPar√°metros:\")\n",
    "print(f\"  Longitud serie (L): {L}\")\n",
    "print(f\"  N√∫mero bootstraps: {N_BOOTSTRAP}\")\n",
    "print(f\"  Lambda exponencial: {lambda_exp:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# FUNCI√ìN PARA GENERAR UNA SERIE BOOTSTRAP\n",
    "# ============================================\n",
    "\n",
    "def generar_serie_bootstrap(serie_original, L, lambda_exp):\n",
    "    \"\"\"\n",
    "    Genera una serie bootstrap usando el m√©todo de bootstrap estacionario\n",
    "    \n",
    "    Par√°metros:\n",
    "    - serie_original: array de longitud L con la serie temporal original\n",
    "    - L: longitud de la serie\n",
    "    - lambda_exp: par√°metro para la distribuci√≥n exponencial\n",
    "    \n",
    "    Retorna:\n",
    "    - serie_bootstrap: array de longitud L con la serie bootstrap\n",
    "    \"\"\"\n",
    "    \n",
    "    serie_bootstrap = np.zeros(L)\n",
    "    pos = 0\n",
    "    \n",
    "    while pos < L:\n",
    "        # 1. Elegir m (punto de inicio) uniformemente\n",
    "        m = np.random.randint(0, L)\n",
    "        \n",
    "        # 2. Elegir l (longitud del bloque) con distribuci√≥n exponencial\n",
    "        l = int(np.random.exponential(scale=1/lambda_exp))\n",
    "        l = min(l, L)  # Asegurar que no excede L\n",
    "        \n",
    "        # 3. Copiar el bloque de longitud l desde m\n",
    "        for i in range(l):\n",
    "            if pos >= L:\n",
    "                break\n",
    "                \n",
    "            # Calcular √≠ndice en la serie original (con wrap-around)\n",
    "            idx_original = (m + i) % L\n",
    "            serie_bootstrap[pos] = serie_original[idx_original]\n",
    "            pos += 1\n",
    "    \n",
    "    return serie_bootstrap\n",
    "\n",
    "def generar_bootstrap_completo(df_original, especies_cols, L, lambda_exp):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame bootstrap completo con todas las especies\n",
    "    \"\"\"\n",
    "    # Crear DataFrame vac√≠o con la misma estructura\n",
    "    df_bootstrap = pd.DataFrame()\n",
    "    df_bootstrap['cal BP'] = df_original['cal BP'].values  # Mantener el tiempo\n",
    "    \n",
    "    # Para cada especie, generar su serie bootstrap\n",
    "    for sp in especies_cols:\n",
    "        if sp in df_original.columns:\n",
    "            serie_original = df_original[sp].values\n",
    "            serie_bootstrap = generar_serie_bootstrap(serie_original, L, lambda_exp)\n",
    "            df_bootstrap[sp] = serie_bootstrap\n",
    "    \n",
    "    return df_bootstrap\n",
    "\n",
    "# ============================================\n",
    "# GENERAR Y GUARDAR BOOTSTRAPS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERANDO BOOTSTRAPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fijar semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generar y guardar cada bootstrap\n",
    "for i in range(1, N_BOOTSTRAP + 1):\n",
    "    print(f\"\\n--- Bootstrap #{i} ---\")\n",
    "    \n",
    "    # Generar bootstrap\n",
    "    df_bootstrap = generar_bootstrap_completo(df_original, especies_cols, L, lambda_exp)\n",
    "    \n",
    "    # Verificar dimensiones\n",
    "    print(f\"  Dimensiones: {df_bootstrap.shape}\")\n",
    "    \n",
    "    # Guardar en archivo pickle\n",
    "    filename = f'pkl/gam_boost_{i}.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(df_bootstrap, f)\n",
    "    \n",
    "    print(f\"  ‚úÖ Guardado en: {filename}\")\n",
    "\n",
    "# ============================================\n",
    "# VERIFICACI√ìN FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICACI√ìN DE ARCHIVOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "archivos = []\n",
    "for i in range(1, N_BOOTSTRAP + 1):\n",
    "    filename = f'pkl/gam_boost_{i}.pkl'\n",
    "    if os.path.exists(filename):\n",
    "        size_kb = os.path.getsize(filename) / 1024\n",
    "        archivos.append((filename, size_kb))\n",
    "\n",
    "print(f\"\\nArchivos en carpeta 'pkl/':\")\n",
    "for filename, size in archivos:\n",
    "    print(f\"  üìÑ {filename} ({size:.1f} KB)\")\n",
    "\n",
    "if len(archivos) == N_BOOTSTRAP:\n",
    "    print(f\"\\n‚úÖ √âXITO: Se generaron los {N_BOOTSTRAP} archivos bootstrap\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è ERROR: Solo se generaron {len(archivos)} de {N_BOOTSTRAP} archivos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCRIPT 1 COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7506791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCRIPT 2: AN√ÅLISIS GRANGER CON BOOTSTRAP POR VENTANAS\n",
      "============================================================\n",
      "\n",
      "Par√°metros:\n",
      "  Umbral p-value: 0.01\n",
      "  N√∫mero bootstraps: 5\n",
      "  Alpha (IC 95%): 0.05\n",
      "  Ventanas: ['9798_6253', '6182_3842', '3771_-57']\n",
      "\n",
      "============================================================\n",
      "PASO 1: CARGANDO DATOS\n",
      "============================================================\n",
      "\n",
      "Cargando datos originales...\n",
      "Especies: 75\n",
      "\n",
      "============================================================\n",
      "PASO 2: CALCULANDO MATRICES ORIGINALES POR VENTANA\n",
      "============================================================\n",
      "\n",
      "--- Ventana: 9798_6253 ---\n",
      "    Ventana 6253-9798: 51 puntos\n",
      "  Puntos en ventana: 51\n",
      "  Calculando matriz 75x75 para 9798_6253...\n",
      "    Progreso: 500/5550\n",
      "    Progreso: 1000/5550\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SCRIPT 2: AN√ÅLISIS GRANGER CON BOOTSTRAP POR VENTANAS\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCRIPT 2: AN√ÅLISIS GRANGER CON BOOTSTRAP POR VENTANAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACI√ìN\n",
    "# ============================================\n",
    "\n",
    "# Ventanas temporales (en t√©rminos de CAL BP, no √≠ndices)\n",
    "windows = {\n",
    "    \"9798_6253\": (9798, 6253),  # Ventana antigua\n",
    "    \"6182_3842\": (6182, 3842),  # Ventana media\n",
    "    \"3771_-57\": (3771, -57)     # Ventana reciente\n",
    "}\n",
    "\n",
    "# Par√°metros\n",
    "UMBRAL_P_VALUE = 0.01  # Para significancia en Granger\n",
    "N_BOOTSTRAP = 5  # Debe coincidir con el script anterior\n",
    "ALPHA = 0.05  # Nivel de significancia (2.5% cada cola)\n",
    "\n",
    "print(f\"\\nPar√°metros:\")\n",
    "print(f\"  Umbral p-value: {UMBRAL_P_VALUE}\")\n",
    "print(f\"  N√∫mero bootstraps: {N_BOOTSTRAP}\")\n",
    "print(f\"  Alpha (IC 95%): {ALPHA}\")\n",
    "print(f\"  Ventanas: {list(windows.keys())}\")\n",
    "\n",
    "# ============================================\n",
    "# FUNCIONES AUXILIARES\n",
    "# ============================================\n",
    "\n",
    "def extraer_ventana(df, cal_min, cal_max):\n",
    "    \"\"\"\n",
    "    Extrae una ventana temporal basada en valores de cal BP\n",
    "    Maneja correctamente rangos donde cal_min > cal_max\n",
    "    \"\"\"\n",
    "    if cal_min > cal_max:\n",
    "        # Ventana con l√≠mite superior e inferior invertidos\n",
    "        mask = (df['cal BP'] >= cal_max) & (df['cal BP'] <= cal_min)\n",
    "    else:\n",
    "        # Ventana normal\n",
    "        mask = (df['cal BP'] >= cal_min) & (df['cal BP'] <= cal_max)\n",
    "    \n",
    "    df_ventana = df[mask].copy().reset_index(drop=True)\n",
    "    print(f\"    Ventana {cal_max}-{cal_min}: {len(df_ventana)} puntos\")\n",
    "    return df_ventana\n",
    "\n",
    "def calcular_coeficiente_granger(df, sp1, sp2):\n",
    "    \"\"\"\n",
    "    Calcula el coeficiente de causalidad de Granger sp1 ‚Üí sp2\n",
    "    Devuelve el coeficiente o None si hay error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Series\n",
    "        array_x = df[sp1].values[::-1]\n",
    "        array_y = df[sp2].values[::-1]\n",
    "        \n",
    "        # Verificar que no son constantes\n",
    "        if np.std(array_x) < 1e-10 or np.std(array_y) < 1e-10:\n",
    "            return None\n",
    "        \n",
    "        # Ruido adaptativo\n",
    "        ruido_x = np.random.normal(0, np.std(array_x) * 1e-6, len(array_x))\n",
    "        ruido_y = np.random.normal(0, np.std(array_y) * 1e-6, len(array_y))\n",
    "        \n",
    "        array_x = array_x + ruido_x\n",
    "        array_y = array_y + ruido_y\n",
    "        \n",
    "        # VAR\n",
    "        data = pd.DataFrame({sp1: array_x, sp2: array_y})\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "        \n",
    "        model = VAR(data_scaled)\n",
    "        results = model.fit(maxlags=1)\n",
    "        \n",
    "        # Coeficiente de sp1 en ecuaci√≥n de sp2\n",
    "        coeficiente = results.coefs[0][1][0]\n",
    "        \n",
    "        return coeficiente\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def calcular_matriz_coeficientes(df, especies_cols, nombre_ventana=\"\"):\n",
    "    \"\"\"\n",
    "    Calcula matriz de coeficientes para todos los pares\n",
    "    \"\"\"\n",
    "    n = len(especies_cols)\n",
    "    matriz = np.zeros((n, n))\n",
    "    \n",
    "    print(f\"  Calculando matriz {n}x{n} para {nombre_ventana}...\")\n",
    "    total_pares = n * (n - 1)\n",
    "    contador = 0\n",
    "    \n",
    "    for i, sp1 in enumerate(especies_cols):\n",
    "        for j, sp2 in enumerate(especies_cols):\n",
    "            if i != j:\n",
    "                coef = calcular_coeficiente_granger(df, sp1, sp2)\n",
    "                if coef is not None:\n",
    "                    matriz[i, j] = coef\n",
    "                \n",
    "                contador += 1\n",
    "                if contador % 500 == 0:\n",
    "                    print(f\"    Progreso: {contador}/{total_pares}\")\n",
    "    \n",
    "    return matriz\n",
    "\n",
    "# ============================================\n",
    "# PASO 1: CARGAR DATOS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1: CARGANDO DATOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar datos originales equidistantes\n",
    "print(\"\\nCargando datos originales...\")\n",
    "with open('pkl/gam_original.pkl', 'rb') as f:\n",
    "    df_original = pickle.load(f)\n",
    "\n",
    "# Identificar especies\n",
    "especies_cols = [col for col in df_original.columns if col != 'cal BP']\n",
    "n_especies = len(especies_cols)\n",
    "print(f\"Especies: {n_especies}\")\n",
    "\n",
    "# ============================================\n",
    "# PASO 2: MATRICES ORIGINALES POR VENTANA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 2: CALCULANDO MATRICES ORIGINALES POR VENTANA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "matrices_originales = {}\n",
    "\n",
    "for window_name, (cal_min, cal_max) in windows.items():\n",
    "    print(f\"\\n--- Ventana: {window_name} ---\")\n",
    "    \n",
    "    # Extraer ventana\n",
    "    df_window = extraer_ventana(df_original, cal_min, cal_max)\n",
    "    print(f\"  Puntos en ventana: {len(df_window)}\")\n",
    "    \n",
    "    # Calcular matriz\n",
    "    matriz = calcular_matriz_coeficientes(df_window, especies_cols, window_name)\n",
    "    matrices_originales[window_name] = matriz\n",
    "    \n",
    "    # Estad√≠sticas b√°sicas\n",
    "    n_pos = np.sum(matriz > 0)\n",
    "    n_neg = np.sum(matriz < 0)\n",
    "    print(f\"  Coeficientes positivos: {n_pos}\")\n",
    "    print(f\"  Coeficientes negativos: {n_neg}\")\n",
    "\n",
    "# Guardar matrices originales\n",
    "with open('matrices_originales_ventanas.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'matrices': matrices_originales,\n",
    "        'especies': especies_cols,\n",
    "        'windows': windows\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Matrices originales guardadas en 'matrices_originales_ventanas.pkl'\")\n",
    "\n",
    "# ============================================\n",
    "# PASO 3: MATRICES BOOTSTRAP POR VENTANA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"PASO 3: CALCULANDO MATRICES BOOTSTRAP POR VENTANA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Estructura para guardar: [ventana][bootstrap][i, j]\n",
    "matrices_bootstrap = {window_name: [] for window_name in windows.keys()}\n",
    "\n",
    "for b in range(1, N_BOOTSTRAP + 1):\n",
    "    print(f\"\\n--- Bootstrap #{b} ---\")\n",
    "    \n",
    "    # Cargar datos bootstrap\n",
    "    filename = f'pkl/gam_boost_{b}.pkl'\n",
    "    with open(filename, 'rb') as f:\n",
    "        df_bootstrap = pickle.load(f)\n",
    "    \n",
    "    for window_name, (cal_min, cal_max) in windows.items():\n",
    "        print(f\"  Ventana: {window_name}\")\n",
    "        \n",
    "        # Extraer ventana\n",
    "        df_window = extraer_ventana(df_bootstrap, cal_min, cal_max)\n",
    "        \n",
    "        # Calcular matriz\n",
    "        matriz = calcular_matriz_coeficientes(df_window, especies_cols, f\"{window_name}_b{b}\")\n",
    "        matrices_bootstrap[window_name].append(matriz)\n",
    "\n",
    "# Convertir a arrays 3D\n",
    "for window_name in windows.keys():\n",
    "    matrices_bootstrap[window_name] = np.array(matrices_bootstrap[window_name])\n",
    "\n",
    "print(f\"\\nDimensiones:\")\n",
    "for window_name in windows.keys():\n",
    "    print(f\"  {window_name}: {matrices_bootstrap[window_name].shape}\")\n",
    "\n",
    "# Guardar matrices bootstrap\n",
    "with open('matrices_bootstrap_ventanas.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'matrices': matrices_bootstrap,\n",
    "        'especies': especies_cols,\n",
    "        'windows': windows,\n",
    "        'n_bootstrap': N_BOOTSTRAP\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Matrices bootstrap guardadas en 'matrices_bootstrap_ventanas.pkl'\")\n",
    "\n",
    "# ============================================\n",
    "# PASO 4: AN√ÅLISIS DE SIGNIFICANCIA POR VENTANA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 4: AN√ÅLISIS DE SIGNIFICANCIA POR VENTANA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for window_name in windows.keys():\n",
    "    print(f\"\\n--- Ventana: {window_name} ---\")\n",
    "    \n",
    "    matriz_orig = matrices_originales[window_name]\n",
    "    matrices_boost = matrices_bootstrap[window_name]\n",
    "    n = n_especies\n",
    "    \n",
    "    # Inicializar matrices de resultados\n",
    "    pct_2_5 = np.zeros((n, n))\n",
    "    pct_97_5 = np.zeros((n, n))\n",
    "    significativo = np.zeros((n, n), dtype=bool)\n",
    "    cola = np.zeros((n, n), dtype='U12')  # 'bajo', 'alto', 'no'\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # Distribuci√≥n bootstrap para este par\n",
    "                valores_boost = matrices_boost[:, i, j]\n",
    "                valores_boost = valores_boost[~np.isnan(valores_boost)]\n",
    "                \n",
    "                if len(valores_boost) >= N_BOOTSTRAP * 0.5:  # Suficientes valores\n",
    "                    # Calcular percentiles\n",
    "                    pct_2_5[i, j] = np.percentile(valores_boost, 2.5)\n",
    "                    pct_97_5[i, j] = np.percentile(valores_boost, 97.5)\n",
    "                    \n",
    "                    # Comparar con valor original\n",
    "                    valor_orig = matriz_orig[i, j]\n",
    "                    \n",
    "                    if valor_orig < pct_2_5[i, j]:\n",
    "                        significativo[i, j] = True\n",
    "                        cola[i, j] = 'bajo'\n",
    "                    elif valor_orig > pct_97_5[i, j]:\n",
    "                        significativo[i, j] = True\n",
    "                        cola[i, j] = 'alto'\n",
    "                    else:\n",
    "                        significativo[i, j] = False\n",
    "                        cola[i, j] = 'no'\n",
    "                else:\n",
    "                    pct_2_5[i, j] = np.nan\n",
    "                    pct_97_5[i, j] = np.nan\n",
    "                    significativo[i, j] = False\n",
    "                    cola[i, j] = 'insuficiente'\n",
    "    \n",
    "    # Guardar resultados para esta ventana\n",
    "    resultados[window_name] = {\n",
    "        'matriz_original': matriz_orig,\n",
    "        'percentil_2_5': pct_2_5,\n",
    "        'percentil_97_5': pct_97_5,\n",
    "        'significativo': significativo,\n",
    "        'cola': cola\n",
    "    }\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    n_pares = n * (n - 1)\n",
    "    n_sig = np.sum(significativo)\n",
    "    n_bajos = np.sum(cola == 'bajo')\n",
    "    n_altos = np.sum(cola == 'alto')\n",
    "    \n",
    "    print(f\"\\n  Resultados:\")\n",
    "    print(f\"    Pares totales: {n_pares}\")\n",
    "    print(f\"    Significativos: {n_sig} ({n_sig/n_pares*100:.2f}%)\")\n",
    "    print(f\"      Cola baja (<2.5%): {n_bajos} ({n_bajos/n_pares*100:.2f}%)\")\n",
    "    print(f\"      Cola alta (>97.5%): {n_altos} ({n_altos/n_pares*100:.2f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# PASO 5: GUARDAR RESULTADOS COMPLETOS\n",
    "# ============================================\n",
    "\n",
    "resultados_completos = {\n",
    "    'especies': especies_cols,\n",
    "    'windows': windows,\n",
    "    'resultados_por_ventana': resultados,\n",
    "    'n_bootstrap': N_BOOTSTRAP,\n",
    "    'alpha': ALPHA\n",
    "}\n",
    "\n",
    "with open('resultados_granger_bootstrap_ventanas.pkl', 'wb') as f:\n",
    "    pickle.dump(resultados_completos, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Resultados completos guardados en 'resultados_granger_bootstrap_ventanas.pkl'\")\n",
    "\n",
    "# ============================================\n",
    "# RESUMEN FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN FINAL - PORCENTAJES POR VENTANA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nVentana        | Total Pares | Significativos | % | Cola baja | Cola alta\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for window_name in windows.keys():\n",
    "    res = resultados[window_name]\n",
    "    n = n_especies\n",
    "    n_pares = n * (n - 1)\n",
    "    n_sig = np.sum(res['significativo'])\n",
    "    n_bajos = np.sum(res['cola'] == 'bajo')\n",
    "    n_altos = np.sum(res['cola'] == 'alto')\n",
    "    \n",
    "    print(f\"{window_name:12} | {n_pares:11} | {n_sig:13} | \"\n",
    "          f\"{n_sig/n_pares*100:5.2f}% | {n_bajos:8} ({n_bajos/n_pares*100:4.1f}%) | \"\n",
    "          f\"{n_altos:8} ({n_altos/n_pares*100:4.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ SCRIPT 2 COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be66199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DIAGN√ìSTICO DE LA FUNCI√ìN GRANGER\n",
      "======================================================================\n",
      "\n",
      "Ventana 9798_6253: 0 puntos\n",
      "\n",
      "Pinus ‚Üí Abies:\n",
      "  Pinus - media: nan, std: nan\n",
      "  Abies - media: nan, std: nan\n",
      "  Primeros 5 valores (invertidos):\n",
      "    Pinus: []\n",
      "    Abies: []\n",
      "  ‚ùå Error: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "Pinus ‚Üí Poaceae:\n",
      "  Pinus - media: nan, std: nan\n",
      "  Poaceae - media: nan, std: nan\n",
      "  Primeros 5 valores (invertidos):\n",
      "    Pinus: []\n",
      "    Poaceae: []\n",
      "  ‚ùå Error: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "Poaceae ‚Üí Artemisia:\n",
      "  Poaceae - media: nan, std: nan\n",
      "  Artemisia - media: nan, std: nan\n",
      "  Primeros 5 valores (invertidos):\n",
      "    Poaceae: []\n",
      "    Artemisia: []\n",
      "  ‚ùå Error: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "Artemisia ‚Üí Chenopodiaceae:\n",
      "  Artemisia - media: nan, std: nan\n",
      "  Chenopodiaceae - media: nan, std: nan\n",
      "  Primeros 5 valores (invertidos):\n",
      "    Artemisia: []\n",
      "    Chenopodiaceae: []\n",
      "  ‚ùå Error: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DIAGN√ìSTICO DE LA FUNCI√ìN GRANGER\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGN√ìSTICO DE LA FUNCI√ìN GRANGER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Cargar datos\n",
    "with open('pkl/gam_original.pkl', 'rb') as f:\n",
    "    df_original = pickle.load(f)\n",
    "\n",
    "# Ventana de ejemplo\n",
    "window_name = \"9798_6253\"\n",
    "cal_min, cal_max = 9798, 6253\n",
    "df_window = df_original[(df_original['cal BP'] >= cal_min) & (df_original['cal BP'] <= cal_max)].copy()\n",
    "\n",
    "print(f\"\\nVentana {window_name}: {len(df_window)} puntos\")\n",
    "\n",
    "# Probar con diferentes pares\n",
    "pares_prueba = [\n",
    "    ('Pinus', 'Abies'),\n",
    "    ('Pinus', 'Poaceae'),\n",
    "    ('Poaceae', 'Artemisia'),\n",
    "    ('Artemisia', 'Chenopodiaceae')\n",
    "]\n",
    "\n",
    "for sp1, sp2 in pares_prueba:\n",
    "    if sp1 not in df_window.columns or sp2 not in df_window.columns:\n",
    "        print(f\"\\n{sp1} ‚Üí {sp2}: ‚ùå Especie no encontrada\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{sp1} ‚Üí {sp2}:\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas b√°sicas de las series\n",
    "    print(f\"  {sp1} - media: {df_window[sp1].mean():.4f}, std: {df_window[sp1].std():.4f}\")\n",
    "    print(f\"  {sp2} - media: {df_window[sp2].mean():.4f}, std: {df_window[sp2].std():.4f}\")\n",
    "    \n",
    "    # Probar c√°lculo manual\n",
    "    try:\n",
    "        array_x = df_window[sp1].values[::-1]\n",
    "        array_y = df_window[sp2].values[::-1]\n",
    "        \n",
    "        print(f\"  Primeros 5 valores (invertidos):\")\n",
    "        print(f\"    {sp1}: {array_x[:5]}\")\n",
    "        print(f\"    {sp2}: {array_y[:5]}\")\n",
    "        \n",
    "        # Verificar si son constantes\n",
    "        if np.std(array_x) < 1e-10:\n",
    "            print(f\"  ‚ö†Ô∏è {sp1} es casi constante (std={np.std(array_x):.6f})\")\n",
    "        if np.std(array_y) < 1e-10:\n",
    "            print(f\"  ‚ö†Ô∏è {sp2} es casi constante (std={np.std(array_y):.6f})\")\n",
    "        \n",
    "        # Ruido\n",
    "        ruido_x = np.random.normal(0, np.std(array_x) * 1e-6, len(array_x))\n",
    "        ruido_y = np.random.normal(0, np.std(array_y) * 1e-6, len(array_y))\n",
    "        \n",
    "        array_x = array_x + ruido_x\n",
    "        array_y = array_y + ruido_y\n",
    "        \n",
    "        # Estandarizar\n",
    "        data = pd.DataFrame({sp1: array_x, sp2: array_y})\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "        \n",
    "        print(f\"  Datos estandarizados - media: {data_scaled.mean().values}, std: {data_scaled.std().values}\")\n",
    "        \n",
    "        # VAR\n",
    "        model = VAR(data_scaled)\n",
    "        results = model.fit(maxlags=1)\n",
    "        \n",
    "        print(f\"  Coeficientes VAR:\")\n",
    "        print(f\"    {sp1}: {results.coefs[0][0]}\")\n",
    "        print(f\"    {sp2}: {results.coefs[0][1]}\")\n",
    "        \n",
    "        coeficiente = results.coefs[0][1][0]\n",
    "        print(f\"  Coeficiente {sp1}‚Üí{sp2}: {coeficiente:.6f}\")\n",
    "        \n",
    "        # Test de causalidad\n",
    "        causality = results.test_causality(caused=sp2, causing=[sp1], kind='f')\n",
    "        print(f\"  p-value: {causality.pvalue:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
